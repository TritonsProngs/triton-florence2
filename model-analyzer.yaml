model_repository: ./

run_config_search_mode: brute
#run_config_search_min_instance_count: 1
#run_config_search_max_instance_count: 2
#run_config_search_min_model_batch_size: 2
#run_config_search_max_model_batch_size: 36
#run_config_search_min_concurrency: 16
#run_config_search_max_concurrency: 64

profile_models:
  florence2_model:
    perf_analyzer_flags:
      input-data: ./triton-florence2/data/load_data_model_MORE_DETAILED_CAPTION.json
      measurement-mode: time_windows
      measurement-interval: 15000
    parameters:
      concurrency:
        start: 12
        stop: 72
        step: 12
    model_config_parameters:
      max_batch_size: [6, 12, 24, 36]
      dynamic_batching:
        max_queue_delay_microseconds: [0, 100, 200]
      instance_group:
        - kind: KIND_GPU
          count: [1, 2]
  florence2_process:
    perf_analyzer_flags:
      input-data: ./triton-florence2/data/load_data_MORE_DETAILED_CAPTION.json
      measurement-mode: time_windows
      measurement-interval: 6000
    parameters:
      concurrency:
        start: 12
        stop: 72
        step: 12
    model_config_parameters:
      max_batch_size: [6, 12, 24, 36]
      dynamic_batching:
        max_queue_delay_microseconds: [0, 100, 200]
      instance_group:
        - kind: KIND_CPU
          count: [1, 2, 3, 4]
  florence2:
    perf_analyzer_flags:
      input-data: ./triton-florence/data/load_data_MORE_DETAILED_CAPTION.json
      measurement-mode: time_windows
      measurement-interval: 15000
    parameters:
      concurrency:
        start: 12
        stop: 72
        step: 12
    model_config_parameters:
      max_batch_size: [6, 12, 24, 36]

    


#perf_analyzer_flags:
#  input-data: ./triton-florence2/data/load_data_model_MORE_DETAILED_CAPTION.json
#  measurement-mode: time_windows
#  measurement-interval: 15000